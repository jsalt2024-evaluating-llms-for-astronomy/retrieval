{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import os\n",
    "import glob\n",
    "from topk_sae import FastAutoencoder, loss_fn, unit_norm_decoder_grad_adjustment_, unit_norm_decoder_, init_from_data_\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(ae, train_loader, optimizer, epochs, k, auxk_coef, clip_grad=None, save_dir=\"checkpoints\", model_name=\"\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    step = 0\n",
    "    num_batches = len(train_loader)\n",
    "    for epoch in range(epochs):\n",
    "        ae.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            optimizer.zero_grad()\n",
    "            x = batch[0].to(device)\n",
    "            recons, info = ae(x)\n",
    "            loss, recons_loss, auxk_loss = loss_fn(ae, x, recons, info, auxk_coef)\n",
    "            loss.backward()\n",
    "            step += 1\n",
    "            \n",
    "            # calculate proportion of dead latents (not fired in last num_batches = 1 epoch)\n",
    "            dead_latents_prop = (ae.stats_last_nonzero > num_batches).float().mean().item()\n",
    "            \n",
    "            unit_norm_decoder_grad_adjustment_(ae)\n",
    "            \n",
    "            if clip_grad is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(ae.parameters(), clip_grad)\n",
    "            \n",
    "            optimizer.step()\n",
    "            unit_norm_decoder_(ae)\n",
    "\n",
    "            topk_indices = torch.cat((info[\"topk_indices\"], info[\"auxk_indices\"]), dim = -1)\n",
    "            selected_grad = torch.abs(ae.encoder.weight.grad[topk_indices, :]).mean()\n",
    "            print('encoder', selected_grad)\n",
    "\n",
    "            mask = torch.ones_like(ae.encoder.weight.grad)\n",
    "            mask[topk_indices, :] = 0\n",
    "            unselected_grad = ae.encoder.weight.grad[mask == 1].mean()\n",
    "            print(unselected_grad)\n",
    "\n",
    "            selected_dgrad = torch.abs(ae.decoder.weight.grad[:, topk_indices]).mean()\n",
    "            print('decoder', selected_dgrad)\n",
    "            unselected_dgrad = ae.decoder.weight.grad[mask.T == 1].mean()\n",
    "            print(unselected_dgrad)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Delete previous model saves for this configuration\n",
    "        for old_model in glob.glob(os.path.join(save_dir, f\"{model_name}_epoch_*.pth\")):\n",
    "            os.remove(old_model)\n",
    "\n",
    "        # Save new model\n",
    "        save_path = os.path.join(save_dir, f\"{model_name}_epoch_{epoch+1}.pth\")\n",
    "        torch.save(ae.state_dict(), save_path)\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "\n",
    "d_model = 1536\n",
    "n_dirs = d_model * 6\n",
    "k = 32\n",
    "auxk = 64 #256\n",
    "batch_size = 1024\n",
    "lr = 1e-4\n",
    "epochs = 1\n",
    "auxk_coef = 1/32\n",
    "clip_grad = 1.0\n",
    "\n",
    "# Create model name\n",
    "model_name = f\"{k}_{n_dirs}_{auxk}_final\"\n",
    "\n",
    "data = np.load(\"../data/vector_store/abstract_embeddings.npy\")\n",
    "data_tensor = torch.from_numpy(data).float()\n",
    "dataset = TensorDataset(data_tensor)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "ae = FastAutoencoder(n_dirs, d_model, k, auxk).to(device)\n",
    "init_from_data_(ae, data_tensor[:10000].to(device))\n",
    "\n",
    "optimizer = optim.Adam(ae.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 0/266 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder tensor(2.4457e-06)\n",
      "tensor(0.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 1/266 [00:03<17:34,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder tensor(8.5545e-06)\n",
      "tensor(0.)\n",
      "encoder tensor(2.2086e-06)\n",
      "tensor(0.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   1%|          | 2/266 [00:07<15:19,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder tensor(8.2827e-06)\n",
      "tensor(0.)\n",
      "encoder tensor(2.0640e-06)\n",
      "tensor(0.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   1%|          | 3/266 [00:10<14:13,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder tensor(8.2802e-06)\n",
      "tensor(0.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   1%|          | 3/266 [00:11<17:08,  3.91s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print abs gradient for topk/auxk and everything else -- encoder and decoder\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauxk_coef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[52], line 29\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(ae, train_loader, optimizer, epochs, k, auxk_coef, clip_grad, save_dir, model_name)\u001b[0m\n\u001b[1;32m     27\u001b[0m recons, info \u001b[38;5;241m=\u001b[39m ae(x)\n\u001b[1;32m     28\u001b[0m loss, recons_loss, auxk_loss \u001b[38;5;241m=\u001b[39m loss_fn(ae, x, recons, info, auxk_coef)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# calculate proportion of dead latents (not fired in last num_batches = 1 epoch)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/jsalt-retrieval/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jsalt-retrieval/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print abs gradient for topk/auxk and everything else -- encoder and decoder\n",
    "\n",
    "train(ae, train_loader, optimizer, epochs, k, auxk_coef, clip_grad, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jsalt-retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
